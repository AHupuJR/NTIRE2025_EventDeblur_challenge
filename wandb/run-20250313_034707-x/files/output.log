2025-03-13 03:47:08,995 INFO: Use wandb logger with id=x; project=your_project_name.
2025-03-13 03:47:09,082 INFO: Dataset initialized with 1771 samples.
2025-03-13 03:47:09,083 INFO: Dataset VoxelnpzPngSingleDeblurDataset - highrev-train is created.
2025-03-13 03:47:09,083 INFO: Use cpu prefetch dataloader: num_prefetch_queue = 2
2025-03-13 03:47:09,084 INFO: Training statistics:
	Number of train images: 1771
	Dataset enlarge ratio: 6
	Batch size per gpu: 8
	World size (gpu number): 4
	Require iter number per epoch: 333
	Total epochs: 601; iters: 200000.
2025-03-13 03:47:09,097 INFO: Dataset initialized with 421 samples.
2025-03-13 03:47:09,097 INFO: Dataset VoxelnpzPngSingleDeblurDataset - highrev-val is created.
2025-03-13 03:47:09,098 INFO: Number of val images/folders in highrev-val: 421
2025-03-13 03:47:09,098 WARNING: pretrain_network path will be ignored during resuming.
2025-03-13 03:47:09,098 INFO: Set pretrain_network_g to /home/ypatel37/cvpr_pj_25/NTIRE2025_EventDeblur_challenge_asu/experiments/KUnet_highrev_single_deblur_voxel/models/net_g_50000.pth
2025-03-13 03:47:14,644 INFO: Network: DistributedDataParallel - KUnet, with parameters: 140,943,581
2025-03-13 03:47:14,644 INFO: KUnet(
  (down1): DownLayer(
    (conv): DoubleConv(
      (conv): Sequential(
        (0): DepthwiseSeparableConv(
          (depthwise): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3)
          (pointwise): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): ConvLayerNorm(
          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (2): ReLU(inplace=True)
        (3): DepthwiseSeparableConv(
          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (4): ConvLayerNorm(
          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (5): ReLU(inplace=True)
      )
    )
    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (down2): DownLayer(
    (conv): DoubleConv(
      (conv): Sequential(
        (0): DepthwiseSeparableConv(
          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): ConvLayerNorm(
          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (2): ReLU(inplace=True)
        (3): DepthwiseSeparableConv(
          (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (4): ConvLayerNorm(
          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (5): ReLU(inplace=True)
      )
    )
    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (down3): DownLayer(
    (conv): DoubleConv(
      (conv): Sequential(
        (0): DepthwiseSeparableConv(
          (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): ConvLayerNorm(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): ReLU(inplace=True)
        (3): DepthwiseSeparableConv(
          (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (4): ConvLayerNorm(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): ReLU(inplace=True)
      )
    )
    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (down4): DownLayer(
    (conv): DoubleConv(
      (conv): Sequential(
        (0): DepthwiseSeparableConv(
          (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (pointwise): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): ConvLayerNorm(
          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ReLU(inplace=True)
        (3): DepthwiseSeparableConv(
          (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (4): ConvLayerNorm(
          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ReLU(inplace=True)
      )
    )
    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (bottleneck): DoubleConv(
    (conv): Sequential(
      (0): DepthwiseSeparableConv(
        (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
        (pointwise): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ConvLayerNorm(
        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (2): ReLU(inplace=True)
      (3): DepthwiseSeparableConv(
        (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
        (pointwise): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
      )
      (4): ConvLayerNorm(
        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (5): ReLU(inplace=True)
    )
  )
  (event_encoder): EventEncoder(
    (conv1): Sequential(
      (0): DepthwiseSeparableConv(
        (depthwise): Conv2d(6, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=6)
        (pointwise): Conv2d(6, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ReLU(inplace=True)
    )
    (conv2): Sequential(
      (0): DepthwiseSeparableConv(
        (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64)
        (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ReLU(inplace=True)
    )
    (conv3): Sequential(
      (0): DepthwiseSeparableConv(
        (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128)
        (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ReLU(inplace=True)
    )
    (conv4): Sequential(
      (0): DepthwiseSeparableConv(
        (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)
        (pointwise): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ReLU(inplace=True)
    )
    (conv5): DepthwiseSeparableConv(
      (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
      (pointwise): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (fusion_layer): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
  (tokenizer): PatchTokenizer(
    (proj): Conv2d(1024, 1024, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (self_attention): TokenSelfAttention(
    (attention): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
    )
    (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (ff): Sequential(
      (0): Linear(in_features=1024, out_features=4096, bias=True)
      (1): ReLU()
      (2): Linear(in_features=4096, out_features=1024, bias=True)
    )
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (token_projection1): KANLinear(
    (base_activation): SiLU()
  )
  (token_projection2): KANLinear(
    (base_activation): SiLU()
  )
  (token_projection3): KANLinear(
    (base_activation): SiLU()
  )
  (up1): UpLayer(
    (up): Up(
      (up_scale): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))
    )
    (conv): DoubleConv(
      (conv): Sequential(
        (0): DepthwiseSeparableConv(
          (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          (pointwise): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): ConvLayerNorm(
          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ReLU(inplace=True)
        (3): DepthwiseSeparableConv(
          (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (4): ConvLayerNorm(
          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ReLU(inplace=True)
      )
    )
  )
  (up2): UpLayer(
    (up): Up(
      (up_scale): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (conv): DoubleConv(
      (conv): Sequential(
        (0): DepthwiseSeparableConv(
          (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (pointwise): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): ConvLayerNorm(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): ReLU(inplace=True)
        (3): DepthwiseSeparableConv(
          (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (4): ConvLayerNorm(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): ReLU(inplace=True)
      )
    )
  )
  (up3): UpLayer(
    (up): Up(
      (up_scale): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))
    )
    (conv): DoubleConv(
      (conv): Sequential(
        (0): DepthwiseSeparableConv(
          (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (pointwise): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): ConvLayerNorm(
          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (2): ReLU(inplace=True)
        (3): DepthwiseSeparableConv(
          (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (4): ConvLayerNorm(
          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (5): ReLU(inplace=True)
      )
    )
  )
  (up4): UpLayer(
    (up): Up(
      (up_scale): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
    )
    (conv): DoubleConv(
      (conv): Sequential(
        (0): DepthwiseSeparableConv(
          (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (pointwise): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): ConvLayerNorm(
          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (2): ReLU(inplace=True)
        (3): DepthwiseSeparableConv(
          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (4): ConvLayerNorm(
          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (5): ReLU(inplace=True)
      )
    )
  )
  (last_conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))
)
2025-03-13 03:47:14,644 INFO: Loading KUnet model from /home/ypatel37/cvpr_pj_25/NTIRE2025_EventDeblur_challenge_asu/experiments/KUnet_highrev_single_deblur_voxel/models/net_g_50000.pth.
 load net keys <built-in method keys of collections.OrderedDict object at 0x1554882434c0>
.. cosineannealingLR
2025-03-13 03:47:15,367 INFO: Model [ImageEventRestorationModel] is created.
2025-03-13 03:47:15,369 INFO: Resuming training from epoch: 489, iter: 50000.
2025-03-13 03:47:31,060 INFO: Start training from epoch: 489, iter: 50000
/home/ypatel37/.local/share/mamba/envs/ntire_env/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv2d(input, weight, bias, self.stride,
/home/ypatel37/.local/share/mamba/envs/ntire_env/lib/python3.9/site-packages/torch/autograd/__init__.py:251: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [3, 64, 1, 1], strides() = [64, 1, 64, 64]
bucket_view.sizes() = [3, 64, 1, 1], strides() = [64, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:320.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2025-03-13 03:54:24,819 INFO: [KUnet..][epoch:489, iter:  50,200, lr:(1.705e-04,1.706e-05,)] [eta: 3 days, 16:54:15, time (data): 3.009 (0.571)] l_pix: -1.7751e+01
2025-03-13 04:01:24,804 INFO: [KUnet..][epoch:490, iter:  50,400, lr:(1.703e-04,1.704e-05,)] [eta: 3 days, 16:01:34, time (data): 0.272 (0.074)] l_pix: -1.8382e+01
2025-03-13 04:07:37,471 INFO: [KUnet..][epoch:490, iter:  50,600, lr:(1.701e-04,1.702e-05,)] [eta: 3 days, 12:23:15, time (data): 4.407 (0.007)] l_pix: -1.8268e+01
2025-03-13 04:14:06,536 INFO: [KUnet..][epoch:491, iter:  50,800, lr:(1.698e-04,1.700e-05,)] [eta: 3 days, 11:21:45, time (data): 3.058 (0.007)] l_pix: -1.6534e+01
2025-03-13 04:20:36,616 INFO: [KUnet..][epoch:492, iter:  51,000, lr:(1.696e-04,1.697e-05,)] [eta: 3 days, 10:44:45, time (data): 2.931 (0.063)] l_pix: -1.7650e+01
2025-03-13 04:26:57,982 INFO: [KUnet..][epoch:492, iter:  51,200, lr:(1.694e-04,1.695e-05,)] [eta: 3 days, 9:59:56, time (data): 0.304 (0.007)] l_pix: -1.7705e+01
2025-03-13 04:34:01,575 INFO: [KUnet..][epoch:493, iter:  51,400, lr:(1.692e-04,1.693e-05,)] [eta: 3 days, 10:40:44, time (data): 0.348 (0.111)] l_pix: -1.7573e+01
2025-03-13 04:40:26,296 INFO: [KUnet..][epoch:493, iter:  51,600, lr:(1.689e-04,1.691e-05,)] [eta: 3 days, 10:09:31, time (data): 4.423 (0.109)] l_pix: -1.8378e+01
2025-03-13 04:47:00,665 INFO: [KUnet..][epoch:494, iter:  51,800, lr:(1.687e-04,1.688e-05,)] [eta: 3 days, 9:57:03, time (data): 0.257 (0.006)] l_pix: -1.9088e+01
2025-03-13 04:53:17,381 INFO: [KUnet..][epoch:495, iter:  52,000, lr:(1.685e-04,1.686e-05,)] [eta: 3 days, 9:24:00, time (data): 1.893 (0.007)] l_pix: -1.8570e+01
2025-03-13 05:00:03,070 INFO: [KUnet..][epoch:495, iter:  52,200, lr:(1.682e-04,1.684e-05,)] [eta: 3 days, 9:28:14, time (data): 3.911 (0.005)] l_pix: -1.7463e+01
2025-03-13 05:06:38,367 INFO: [KUnet..][epoch:496, iter:  52,400, lr:(1.680e-04,1.682e-05,)] [eta: 3 days, 9:20:00, time (data): 6.286 (6.053)] l_pix: -1.7030e+01
2025-03-13 05:12:36,065 INFO: [KUnet..][epoch:496, iter:  52,600, lr:(1.678e-04,1.679e-05,)] [eta: 3 days, 8:36:30, time (data): 1.827 (1.531)] l_pix: -1.8161e+01
2025-03-13 05:19:31,068 INFO: [KUnet..][epoch:497, iter:  52,800, lr:(1.676e-04,1.677e-05,)] [eta: 3 days, 8:48:33, time (data): 4.796 (0.007)] l_pix: -1.7547e+01
2025-03-13 05:26:03,295 INFO: [KUnet..][epoch:498, iter:  53,000, lr:(1.673e-04,1.675e-05,)] [eta: 3 days, 8:39:29, time (data): 1.118 (0.015)] l_pix: -1.8261e+01
2025-03-13 05:32:19,740 INFO: [KUnet..][epoch:498, iter:  53,200, lr:(1.671e-04,1.672e-05,)] [eta: 3 days, 8:18:40, time (data): 5.161 (4.896)] l_pix: -1.8609e+01
2025-03-13 05:38:55,945 INFO: [KUnet..][epoch:499, iter:  53,400, lr:(1.669e-04,1.670e-05,)] [eta: 3 days, 8:13:46, time (data): 0.191 (0.005)] l_pix: -1.7956e+01
2025-03-13 05:44:49,780 INFO: [KUnet..][epoch:499, iter:  53,600, lr:(1.666e-04,1.668e-05,)] [eta: 3 days, 7:39:57, time (data): 0.251 (0.007)] l_pix: -1.9510e+01
2025-03-13 05:51:18,786 INFO: [KUnet..][epoch:500, iter:  53,800, lr:(1.664e-04,1.665e-05,)] [eta: 3 days, 7:31:38, time (data): 5.532 (5.292)] l_pix: -1.8292e+01
2025-03-13 05:57:25,543 INFO: [KUnet..][epoch:501, iter:  54,000, lr:(1.661e-04,1.663e-05,)] [eta: 3 days, 7:09:58, time (data): 4.621 (4.420)] l_pix: -1.8581e+01
2025-03-13 06:03:43,545 INFO: [KUnet..][epoch:501, iter:  54,200, lr:(1.659e-04,1.661e-05,)] [eta: 3 days, 6:56:17, time (data): 0.217 (0.008)] l_pix: -1.7992e+01
2025-03-13 06:10:30,902 INFO: [KUnet..][epoch:502, iter:  54,400, lr:(1.657e-04,1.658e-05,)] [eta: 3 days, 6:59:27, time (data): 0.305 (0.005)] l_pix: -1.7677e+01
2025-03-13 06:16:48,209 INFO: [KUnet..][epoch:502, iter:  54,600, lr:(1.654e-04,1.656e-05,)] [eta: 3 days, 6:45:56, time (data): 0.243 (0.008)] l_pix: -1.7509e+01
2025-03-13 06:23:36,668 INFO: [KUnet..][epoch:503, iter:  54,800, lr:(1.652e-04,1.654e-05,)] [eta: 3 days, 6:48:43, time (data): 0.280 (0.025)] l_pix: -1.8139e+01
2025-03-13 06:30:01,131 INFO: [KUnet..][epoch:504, iter:  55,000, lr:(1.650e-04,1.651e-05,)] [eta: 3 days, 6:39:08, time (data): 0.506 (0.008)] l_pix: -1.7511e+01
2025-03-13 06:36:30,279 INFO: [KUnet..][epoch:504, iter:  55,200, lr:(1.647e-04,1.649e-05,)] [eta: 3 days, 6:31:58, time (data): 3.695 (3.456)] l_pix: -1.9045e+01
2025-03-13 06:43:13,406 INFO: [KUnet..][epoch:505, iter:  55,400, lr:(1.645e-04,1.646e-05,)] [eta: 3 days, 6:31:06, time (data): 0.857 (0.008)] l_pix: -1.8277e+01
2025-03-13 06:49:19,147 INFO: [KUnet..][epoch:505, iter:  55,600, lr:(1.642e-04,1.644e-05,)] [eta: 3 days, 6:13:45, time (data): 0.349 (0.063)] l_pix: -1.7070e+01
2025-03-13 06:56:14,960 INFO: [KUnet..][epoch:506, iter:  55,800, lr:(1.640e-04,1.642e-05,)] [eta: 3 days, 6:17:55, time (data): 4.938 (4.603)] l_pix: -1.7718e+01
2025-03-13 07:02:26,160 INFO: [KUnet..][epoch:507, iter:  56,000, lr:(1.638e-04,1.639e-05,)] [eta: 3 days, 6:03:30, time (data): 4.518 (0.085)] l_pix: -1.7054e+01
2025-03-13 07:09:14,035 INFO: [KUnet..][epoch:507, iter:  56,200, lr:(1.635e-04,1.637e-05,)] [eta: 3 days, 6:03:47, time (data): 0.309 (0.011)] l_pix: -1.8762e+01
2025-03-13 07:16:05,442 INFO: [KUnet..][epoch:508, iter:  56,400, lr:(1.633e-04,1.634e-05,)] [eta: 3 days, 6:04:57, time (data): 5.479 (5.289)] l_pix: -1.8741e+01
2025-03-13 07:22:04,568 INFO: [KUnet..][epoch:508, iter:  56,600, lr:(1.630e-04,1.632e-05,)] [eta: 3 days, 5:46:42, time (data): 0.601 (0.006)] l_pix: -1.8392e+01
2025-03-13 07:28:54,615 INFO: [KUnet..][epoch:509, iter:  56,800, lr:(1.628e-04,1.630e-05,)] [eta: 3 days, 5:47:03, time (data): 5.264 (5.041)] l_pix: -1.8220e+01
2025-03-13 07:34:59,318 INFO: [KUnet..][epoch:510, iter:  57,000, lr:(1.625e-04,1.627e-05,)] [eta: 3 days, 5:31:33, time (data): 4.513 (4.309)] l_pix: -1.8375e+01
2025-03-13 07:41:05,206 INFO: [KUnet..][epoch:510, iter:  57,200, lr:(1.623e-04,1.625e-05,)] [eta: 3 days, 5:16:57, time (data): 5.143 (4.900)] l_pix: -1.9191e+01
2025-03-13 07:47:51,202 INFO: [KUnet..][epoch:511, iter:  57,400, lr:(1.621e-04,1.622e-05,)] [eta: 3 days, 5:15:42, time (data): 0.403 (0.021)] l_pix: -1.8499e+01
2025-03-13 07:54:07,666 INFO: [KUnet..][epoch:511, iter:  57,600, lr:(1.618e-04,1.620e-05,)] [eta: 3 days, 5:04:57, time (data): 0.325 (0.006)] l_pix: -1.8736e+01
2025-03-13 08:00:44,676 INFO: [KUnet..][epoch:512, iter:  57,800, lr:(1.616e-04,1.617e-05,)] [eta: 3 days, 5:00:39, time (data): 1.964 (0.008)] l_pix: -1.8532e+01
2025-03-13 08:06:48,980 INFO: [KUnet..][epoch:513, iter:  58,000, lr:(1.613e-04,1.615e-05,)] [eta: 3 days, 4:46:35, time (data): 0.236 (0.008)] l_pix: -1.8118e+01
2025-03-13 08:12:47,020 INFO: [KUnet..][epoch:513, iter:  58,200, lr:(1.611e-04,1.612e-05,)] [eta: 3 days, 4:31:05, time (data): 4.857 (0.050)] l_pix: -1.7356e+01
2025-03-13 08:19:25,875 INFO: [KUnet..][epoch:514, iter:  58,400, lr:(1.608e-04,1.610e-05,)] [eta: 3 days, 4:27:30, time (data): 6.058 (0.006)] l_pix: -1.7534e+01
2025-03-13 08:25:37,895 INFO: [KUnet..][epoch:514, iter:  58,600, lr:(1.606e-04,1.607e-05,)] [eta: 3 days, 4:16:26, time (data): 0.338 (0.011)] l_pix: -1.8846e+01
2025-03-13 08:32:26,387 INFO: [KUnet..][epoch:515, iter:  58,800, lr:(1.603e-04,1.605e-05,)] [eta: 3 days, 4:15:20, time (data): 0.284 (0.073)] l_pix: -1.8456e+01
2025-03-13 08:39:20,325 INFO: [KUnet..][epoch:516, iter:  59,000, lr:(1.601e-04,1.602e-05,)] [eta: 3 days, 4:15:25, time (data): 0.437 (0.006)] l_pix: -1.6889e+01
2025-03-13 08:45:50,219 INFO: [KUnet..][epoch:516, iter:  59,200, lr:(1.598e-04,1.600e-05,)] [eta: 3 days, 4:09:03, time (data): 0.545 (0.029)] l_pix: -1.8335e+01
2025-03-13 16:52:33,930 INFO: [KUnet..][epoch:517, iter:  59,400, lr:(1.596e-04,1.597e-05,)] [eta: 8 days, 3:44:53, time (data): 0.278 (0.006)] l_pix: -1.8416e+01
2025-03-13 16:58:51,315 INFO: [KUnet..][epoch:517, iter:  59,600, lr:(1.593e-04,1.595e-05,)] [eta: 8 days, 0:55:50, time (data): 3.830 (0.005)] l_pix: -1.8137e+01
2025-03-13 17:05:29,574 INFO: [KUnet..][epoch:518, iter:  59,800, lr:(1.591e-04,1.592e-05,)] [eta: 7 days, 22:18:25, time (data): 0.420 (0.006)] l_pix: -1.8558e+01
2025-03-13 17:11:47,785 INFO: [KUnet..][epoch:519, iter:  60,000, lr:(1.588e-04,1.590e-05,)] [eta: 7 days, 19:42:21, time (data): 1.943 (1.649)] l_pix: -1.8462e+01
2025-03-13 17:11:47,814 INFO: Saving models and training states.
2025-03-13 17:17:43,633 INFO: [KUnet..][epoch:519, iter:  60,200, lr:(1.585e-04,1.587e-05,)] [eta: 7 days, 17:07:03, time (data): 4.315 (4.101)] l_pix: -1.8318e+01
2025-03-13 17:24:05,944 INFO: [KUnet..][epoch:520, iter:  60,400, lr:(1.583e-04,1.585e-05,)] [eta: 7 days, 14:43:24, time (data): 3.793 (3.600)] l_pix: -1.9028e+01
2025-03-13 17:29:50,410 INFO: [KUnet..][epoch:520, iter:  60,600, lr:(1.580e-04,1.582e-05,)] [eta: 7 days, 12:16:39, time (data): 4.402 (4.127)] l_pix: -1.8167e+01
2025-03-13 17:36:23,766 INFO: [KUnet..][epoch:521, iter:  60,800, lr:(1.578e-04,1.580e-05,)] [eta: 7 days, 10:05:37, time (data): 5.325 (5.132)] l_pix: -1.9004e+01
2025-03-13 17:42:30,490 INFO: [KUnet..][epoch:522, iter:  61,000, lr:(1.575e-04,1.577e-05,)] [eta: 7 days, 7:53:30, time (data): 5.230 (4.960)] l_pix: -1.7641e+01
2025-03-13 17:48:49,665 INFO: [KUnet..][epoch:522, iter:  61,200, lr:(1.573e-04,1.575e-05,)] [eta: 7 days, 5:48:28, time (data): 3.248 (2.388)] l_pix: -1.8160e+01
