2025-03-12 21:34:51,368 INFO: Use wandb logger with id=x; project=your_project_name.
2025-03-12 21:34:51,430 INFO: Dataset initialized with 1771 samples.
2025-03-12 21:34:51,430 INFO: Dataset VoxelnpzPngSingleDeblurDataset - highrev-train is created.
2025-03-12 21:34:51,430 INFO: Use cpu prefetch dataloader: num_prefetch_queue = 2
2025-03-12 21:34:51,431 INFO: Training statistics:
	Number of train images: 1771
	Dataset enlarge ratio: 6
	Batch size per gpu: 8
	World size (gpu number): 4
	Require iter number per epoch: 333
	Total epochs: 601; iters: 200000.
2025-03-12 21:34:51,443 INFO: Dataset initialized with 421 samples.
2025-03-12 21:34:51,443 INFO: Dataset VoxelnpzPngSingleDeblurDataset - highrev-val is created.
2025-03-12 21:34:51,444 INFO: Number of val images/folders in highrev-val: 421
2025-03-12 21:34:51,444 WARNING: pretrain_network path will be ignored during resuming.
2025-03-12 21:34:51,445 INFO: Set pretrain_network_g to /home/ypatel37/cvpr_pj_25/NTIRE2025_EventDeblur_challenge_asu/experiments/KUnet_highrev_single_deblur_voxel/models/net_g_40000.pth
2025-03-12 21:34:57,322 INFO: Network: DistributedDataParallel - KUnet, with parameters: 140,943,581
2025-03-12 21:34:57,322 INFO: KUnet(
  (down1): DownLayer(
    (conv): DoubleConv(
      (conv): Sequential(
        (0): DepthwiseSeparableConv(
          (depthwise): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3)
          (pointwise): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): ConvLayerNorm(
          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (2): ReLU(inplace=True)
        (3): DepthwiseSeparableConv(
          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (4): ConvLayerNorm(
          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (5): ReLU(inplace=True)
      )
    )
    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (down2): DownLayer(
    (conv): DoubleConv(
      (conv): Sequential(
        (0): DepthwiseSeparableConv(
          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): ConvLayerNorm(
          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (2): ReLU(inplace=True)
        (3): DepthwiseSeparableConv(
          (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (4): ConvLayerNorm(
          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (5): ReLU(inplace=True)
      )
    )
    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (down3): DownLayer(
    (conv): DoubleConv(
      (conv): Sequential(
        (0): DepthwiseSeparableConv(
          (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): ConvLayerNorm(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): ReLU(inplace=True)
        (3): DepthwiseSeparableConv(
          (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (4): ConvLayerNorm(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): ReLU(inplace=True)
      )
    )
    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (down4): DownLayer(
    (conv): DoubleConv(
      (conv): Sequential(
        (0): DepthwiseSeparableConv(
          (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (pointwise): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): ConvLayerNorm(
          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ReLU(inplace=True)
        (3): DepthwiseSeparableConv(
          (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (4): ConvLayerNorm(
          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ReLU(inplace=True)
      )
    )
    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (bottleneck): DoubleConv(
    (conv): Sequential(
      (0): DepthwiseSeparableConv(
        (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
        (pointwise): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ConvLayerNorm(
        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (2): ReLU(inplace=True)
      (3): DepthwiseSeparableConv(
        (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
        (pointwise): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
      )
      (4): ConvLayerNorm(
        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (5): ReLU(inplace=True)
    )
  )
  (event_encoder): EventEncoder(
    (conv1): Sequential(
      (0): DepthwiseSeparableConv(
        (depthwise): Conv2d(6, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=6)
        (pointwise): Conv2d(6, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ReLU(inplace=True)
    )
    (conv2): Sequential(
      (0): DepthwiseSeparableConv(
        (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64)
        (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ReLU(inplace=True)
    )
    (conv3): Sequential(
      (0): DepthwiseSeparableConv(
        (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128)
        (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ReLU(inplace=True)
    )
    (conv4): Sequential(
      (0): DepthwiseSeparableConv(
        (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)
        (pointwise): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ReLU(inplace=True)
    )
    (conv5): DepthwiseSeparableConv(
      (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
      (pointwise): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (fusion_layer): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
  (tokenizer): PatchTokenizer(
    (proj): Conv2d(1024, 1024, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (self_attention): TokenSelfAttention(
    (attention): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
    )
    (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (ff): Sequential(
      (0): Linear(in_features=1024, out_features=4096, bias=True)
      (1): ReLU()
      (2): Linear(in_features=4096, out_features=1024, bias=True)
    )
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (token_projection1): KANLinear(
    (base_activation): SiLU()
  )
  (token_projection2): KANLinear(
    (base_activation): SiLU()
  )
  (token_projection3): KANLinear(
    (base_activation): SiLU()
  )
  (up1): UpLayer(
    (up): Up(
      (up_scale): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))
    )
    (conv): DoubleConv(
      (conv): Sequential(
        (0): DepthwiseSeparableConv(
          (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          (pointwise): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): ConvLayerNorm(
          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ReLU(inplace=True)
        (3): DepthwiseSeparableConv(
          (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (4): ConvLayerNorm(
          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ReLU(inplace=True)
      )
    )
  )
  (up2): UpLayer(
    (up): Up(
      (up_scale): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (conv): DoubleConv(
      (conv): Sequential(
        (0): DepthwiseSeparableConv(
          (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (pointwise): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): ConvLayerNorm(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): ReLU(inplace=True)
        (3): DepthwiseSeparableConv(
          (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (4): ConvLayerNorm(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): ReLU(inplace=True)
      )
    )
  )
  (up3): UpLayer(
    (up): Up(
      (up_scale): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))
    )
    (conv): DoubleConv(
      (conv): Sequential(
        (0): DepthwiseSeparableConv(
          (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (pointwise): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): ConvLayerNorm(
          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (2): ReLU(inplace=True)
        (3): DepthwiseSeparableConv(
          (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (4): ConvLayerNorm(
          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (5): ReLU(inplace=True)
      )
    )
  )
  (up4): UpLayer(
    (up): Up(
      (up_scale): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
    )
    (conv): DoubleConv(
      (conv): Sequential(
        (0): DepthwiseSeparableConv(
          (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (pointwise): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): ConvLayerNorm(
          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (2): ReLU(inplace=True)
        (3): DepthwiseSeparableConv(
          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (4): ConvLayerNorm(
          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (5): ReLU(inplace=True)
      )
    )
  )
  (last_conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))
)
2025-03-12 21:34:57,323 INFO: Loading KUnet model from /home/ypatel37/cvpr_pj_25/NTIRE2025_EventDeblur_challenge_asu/experiments/KUnet_highrev_single_deblur_voxel/models/net_g_40000.pth.
 load net keys <built-in method keys of collections.OrderedDict object at 0x1554882584c0>
.. cosineannealingLR
2025-03-12 21:34:58,310 INFO: Model [ImageEventRestorationModel] is created.
2025-03-12 21:34:58,312 INFO: Resuming training from epoch: 459, iter: 40000.
2025-03-12 21:35:10,443 INFO: Start training from epoch: 459, iter: 40000
/home/ypatel37/.local/share/mamba/envs/ntire_env/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv2d(input, weight, bias, self.stride,
/home/ypatel37/.local/share/mamba/envs/ntire_env/lib/python3.9/site-packages/torch/autograd/__init__.py:251: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [3, 64, 1, 1], strides() = [64, 1, 64, 64]
bucket_view.sizes() = [3, 64, 1, 1], strides() = [64, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:320.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2025-03-12 21:41:58,917 INFO: [KUnet..][epoch:459, iter:  40,200, lr:(1.807e-04,1.808e-05,)] [eta: 3 days, 20:53:09, time (data): 0.361 (0.006)] l_pix: -1.7685e+01
2025-03-12 21:48:19,071 INFO: [KUnet..][epoch:460, iter:  40,400, lr:(1.805e-04,1.806e-05,)] [eta: 3 days, 16:31:43, time (data): 0.338 (0.006)] l_pix: -1.8114e+01
2025-03-12 21:54:42,545 INFO: [KUnet..][epoch:460, iter:  40,600, lr:(1.804e-04,1.804e-05,)] [eta: 3 days, 15:14:45, time (data): 0.367 (0.020)] l_pix: -1.8443e+01
2025-03-12 22:01:10,925 INFO: [KUnet..][epoch:461, iter:  40,800, lr:(1.802e-04,1.803e-05,)] [eta: 3 days, 14:49:17, time (data): 0.294 (0.023)] l_pix: -1.6674e+01
2025-03-12 22:07:17,139 INFO: [KUnet..][epoch:462, iter:  41,000, lr:(1.800e-04,1.801e-05,)] [eta: 3 days, 13:32:43, time (data): 5.760 (0.798)] l_pix: -1.7556e+01
2025-03-12 22:13:56,312 INFO: [KUnet..][epoch:462, iter:  41,200, lr:(1.798e-04,1.799e-05,)] [eta: 3 days, 13:52:15, time (data): 1.130 (0.010)] l_pix: -1.7575e+01
2025-03-12 22:20:49,325 INFO: [KUnet..][epoch:463, iter:  41,400, lr:(1.796e-04,1.797e-05,)] [eta: 3 days, 14:30:26, time (data): 0.348 (0.008)] l_pix: -1.8055e+01
2025-03-12 22:27:24,178 INFO: [KUnet..][epoch:463, iter:  41,600, lr:(1.794e-04,1.795e-05,)] [eta: 3 days, 14:27:24, time (data): 1.532 (0.005)] l_pix: -1.7953e+01
2025-03-12 22:34:05,499 INFO: [KUnet..][epoch:464, iter:  41,800, lr:(1.792e-04,1.793e-05,)] [eta: 3 days, 14:33:03, time (data): 0.374 (0.028)] l_pix: -1.8292e+01
2025-03-12 22:40:27,198 INFO: [KUnet..][epoch:465, iter:  42,000, lr:(1.790e-04,1.791e-05,)] [eta: 3 days, 14:10:24, time (data): 1.980 (1.792)] l_pix: -1.8740e+01
2025-03-12 22:46:32,770 INFO: [KUnet..][epoch:465, iter:  42,200, lr:(1.788e-04,1.789e-05,)] [eta: 3 days, 13:31:27, time (data): 3.835 (0.069)] l_pix: -1.8026e+01
2025-03-12 22:53:12,065 INFO: [KUnet..][epoch:466, iter:  42,400, lr:(1.786e-04,1.787e-05,)] [eta: 3 days, 13:34:52, time (data): 0.480 (0.005)] l_pix: -1.9105e+01
2025-03-12 22:59:07,758 INFO: [KUnet..][epoch:466, iter:  42,600, lr:(1.784e-04,1.785e-05,)] [eta: 3 days, 12:52:46, time (data): 4.433 (0.006)] l_pix: -1.8661e+01
2025-03-12 23:05:46,061 INFO: [KUnet..][epoch:467, iter:  42,800, lr:(1.783e-04,1.783e-05,)] [eta: 3 days, 12:55:41, time (data): 0.298 (0.005)] l_pix: -1.7041e+01
2025-03-12 23:12:13,236 INFO: [KUnet..][epoch:468, iter:  43,000, lr:(1.781e-04,1.782e-05,)] [eta: 3 days, 12:47:37, time (data): 0.302 (0.007)] l_pix: -1.8337e+01
2025-03-12 23:18:22,930 INFO: [KUnet..][epoch:468, iter:  43,200, lr:(1.779e-04,1.780e-05,)] [eta: 3 days, 12:25:29, time (data): 0.417 (0.005)] l_pix: -1.7558e+01
2025-03-12 23:24:55,526 INFO: [KUnet..][epoch:469, iter:  43,400, lr:(1.777e-04,1.778e-05,)] [eta: 3 days, 12:22:48, time (data): 0.256 (0.007)] l_pix: -1.7482e+01
2025-03-12 23:31:08,172 INFO: [KUnet..][epoch:469, iter:  43,600, lr:(1.775e-04,1.776e-05,)] [eta: 3 days, 12:05:15, time (data): 4.930 (1.031)] l_pix: -1.8526e+01
2025-03-12 23:37:41,596 INFO: [KUnet..][epoch:470, iter:  43,800, lr:(1.773e-04,1.774e-05,)] [eta: 3 days, 12:03:08, time (data): 0.933 (0.006)] l_pix: -1.7379e+01
2025-03-12 23:44:11,275 INFO: [KUnet..][epoch:471, iter:  44,000, lr:(1.771e-04,1.772e-05,)] [eta: 3 days, 11:58:08, time (data): 3.536 (0.009)] l_pix: -1.7940e+01
2025-03-12 23:50:49,097 INFO: [KUnet..][epoch:471, iter:  44,200, lr:(1.769e-04,1.770e-05,)] [eta: 3 days, 11:58:01, time (data): 4.190 (0.006)] l_pix: -1.7898e+01
2025-03-12 23:57:45,727 INFO: [KUnet..][epoch:472, iter:  44,400, lr:(1.767e-04,1.768e-05,)] [eta: 3 days, 12:08:24, time (data): 0.347 (0.006)] l_pix: -1.8297e+01
2025-03-13 00:04:09,824 INFO: [KUnet..][epoch:472, iter:  44,600, lr:(1.765e-04,1.766e-05,)] [eta: 3 days, 11:58:57, time (data): 0.249 (0.005)] l_pix: -1.7216e+01
2025-03-13 00:10:47,917 INFO: [KUnet..][epoch:473, iter:  44,800, lr:(1.763e-04,1.764e-05,)] [eta: 3 days, 11:57:18, time (data): 0.266 (0.010)] l_pix: -1.7612e+01
2025-03-13 00:17:12,779 INFO: [KUnet..][epoch:474, iter:  45,000, lr:(1.761e-04,1.762e-05,)] [eta: 3 days, 11:48:26, time (data): 6.241 (1.805)] l_pix: -1.8137e+01
2025-03-13 00:17:12,784 INFO: Saving models and training states.
2025-03-13 00:23:13,860 INFO: [KUnet..][epoch:474, iter:  45,200, lr:(1.758e-04,1.760e-05,)] [eta: 3 days, 11:27:56, time (data): 0.288 (0.008)] l_pix: -1.8874e+01
2025-03-13 00:29:22,087 INFO: [KUnet..][epoch:475, iter:  45,400, lr:(1.756e-04,1.758e-05,)] [eta: 3 days, 11:11:56, time (data): 3.263 (2.900)] l_pix: -1.7697e+01
2025-03-13 00:35:26,456 INFO: [KUnet..][epoch:475, iter:  45,600, lr:(1.754e-04,1.755e-05,)] [eta: 3 days, 10:54:52, time (data): 0.411 (0.157)] l_pix: -1.8651e+01
2025-03-13 00:42:09,435 INFO: [KUnet..][epoch:476, iter:  45,800, lr:(1.752e-04,1.753e-05,)] [eta: 3 days, 10:55:39, time (data): 0.298 (0.024)] l_pix: -1.8152e+01
2025-03-13 00:48:31,125 INFO: [KUnet..][epoch:477, iter:  46,000, lr:(1.750e-04,1.751e-05,)] [eta: 3 days, 10:46:50, time (data): 0.272 (0.005)] l_pix: -1.7448e+01
2025-03-13 00:54:29,771 INFO: [KUnet..][epoch:477, iter:  46,200, lr:(1.748e-04,1.749e-05,)] [eta: 3 days, 10:28:39, time (data): 1.178 (0.031)] l_pix: -1.7681e+01
2025-03-13 01:01:01,273 INFO: [KUnet..][epoch:478, iter:  46,400, lr:(1.746e-04,1.747e-05,)] [eta: 3 days, 10:24:22, time (data): 4.302 (0.009)] l_pix: -1.8667e+01
2025-03-13 01:06:57,854 INFO: [KUnet..][epoch:478, iter:  46,600, lr:(1.744e-04,1.745e-05,)] [eta: 3 days, 10:06:26, time (data): 0.369 (0.009)] l_pix: -1.8649e+01
2025-03-13 01:13:32,424 INFO: [KUnet..][epoch:479, iter:  46,800, lr:(1.742e-04,1.743e-05,)] [eta: 3 days, 10:03:27, time (data): 0.251 (0.016)] l_pix: -1.7166e+01
2025-03-13 01:20:04,091 INFO: [KUnet..][epoch:480, iter:  47,000, lr:(1.740e-04,1.741e-05,)] [eta: 3 days, 9:59:13, time (data): 5.204 (3.167)] l_pix: -1.7483e+01
2025-03-13 01:26:12,637 INFO: [KUnet..][epoch:480, iter:  47,200, lr:(1.738e-04,1.739e-05,)] [eta: 3 days, 9:46:41, time (data): 0.782 (0.007)] l_pix: -1.8346e+01
2025-03-13 01:32:51,788 INFO: [KUnet..][epoch:481, iter:  47,400, lr:(1.736e-04,1.737e-05,)] [eta: 3 days, 9:45:00, time (data): 0.286 (0.010)] l_pix: -1.8351e+01
2025-03-13 01:39:11,826 INFO: [KUnet..][epoch:481, iter:  47,600, lr:(1.733e-04,1.735e-05,)] [eta: 3 days, 9:36:40, time (data): 0.211 (0.005)] l_pix: -1.8157e+01
2025-03-13 01:45:43,595 INFO: [KUnet..][epoch:482, iter:  47,800, lr:(1.731e-04,1.732e-05,)] [eta: 3 days, 9:32:16, time (data): 0.310 (0.019)] l_pix: -1.7738e+01
2025-03-13 01:52:11,781 INFO: [KUnet..][epoch:483, iter:  48,000, lr:(1.729e-04,1.730e-05,)] [eta: 3 days, 9:26:37, time (data): 0.354 (0.006)] l_pix: -1.7442e+01
2025-03-13 01:58:02,726 INFO: [KUnet..][epoch:483, iter:  48,200, lr:(1.727e-04,1.728e-05,)] [eta: 3 days, 9:09:26, time (data): 4.684 (0.006)] l_pix: -1.8430e+01
2025-03-13 02:04:52,714 INFO: [KUnet..][epoch:484, iter:  48,400, lr:(1.725e-04,1.726e-05,)] [eta: 3 days, 9:10:33, time (data): 5.400 (0.015)] l_pix: -1.8383e+01
2025-03-13 02:11:04,370 INFO: [KUnet..][epoch:484, iter:  48,600, lr:(1.723e-04,1.724e-05,)] [eta: 3 days, 9:00:03, time (data): 0.411 (0.010)] l_pix: -1.9042e+01
2025-03-13 02:17:43,764 INFO: [KUnet..][epoch:485, iter:  48,800, lr:(1.720e-04,1.722e-05,)] [eta: 3 days, 8:57:42, time (data): 0.616 (0.351)] l_pix: -1.8341e+01
2025-03-13 02:23:51,856 INFO: [KUnet..][epoch:486, iter:  49,000, lr:(1.718e-04,1.720e-05,)] [eta: 3 days, 8:46:24, time (data): 2.329 (0.007)] l_pix: -1.6768e+01
2025-03-13 02:30:27,846 INFO: [KUnet..][epoch:486, iter:  49,200, lr:(1.716e-04,1.717e-05,)] [eta: 3 days, 8:42:56, time (data): 5.250 (0.072)] l_pix: -1.8573e+01
2025-03-13 02:37:08,871 INFO: [KUnet..][epoch:487, iter:  49,400, lr:(1.714e-04,1.715e-05,)] [eta: 3 days, 8:40:41, time (data): 0.385 (0.072)] l_pix: -1.7953e+01
2025-03-13 02:43:01,505 INFO: [KUnet..][epoch:487, iter:  49,600, lr:(1.712e-04,1.713e-05,)] [eta: 3 days, 8:25:37, time (data): 4.944 (4.701)] l_pix: -1.7793e+01
2025-03-13 02:49:34,857 INFO: [KUnet..][epoch:488, iter:  49,800, lr:(1.709e-04,1.711e-05,)] [eta: 3 days, 8:21:20, time (data): 2.335 (0.344)] l_pix: -1.8500e+01
2025-03-13 02:55:45,132 INFO: [KUnet..][epoch:489, iter:  50,000, lr:(1.707e-04,1.709e-05,)] [eta: 3 days, 8:11:11, time (data): 3.781 (0.010)] l_pix: -1.8662e+01
2025-03-13 02:55:45,133 INFO: Saving models and training states.
2025-03-13 03:02:10,311 INFO: [KUnet..][epoch:489, iter:  50,200, lr:(1.705e-04,1.706e-05,)] [eta: 3 days, 8:04:50, time (data): 0.415 (0.007)] l_pix: -1.7956e+01
2025-03-13 03:08:59,113 INFO: [KUnet..][epoch:490, iter:  50,400, lr:(1.703e-04,1.704e-05,)] [eta: 3 days, 8:04:09, time (data): 5.784 (0.011)] l_pix: -1.8248e+01
2025-03-13 03:15:02,841 INFO: [KUnet..][epoch:490, iter:  50,600, lr:(1.701e-04,1.702e-05,)] [eta: 3 days, 7:52:39, time (data): 3.905 (0.008)] l_pix: -1.8059e+01
2025-03-13 03:21:33,369 INFO: [KUnet..][epoch:491, iter:  50,800, lr:(1.698e-04,1.700e-05,)] [eta: 3 days, 7:47:31, time (data): 0.225 (0.017)] l_pix: -1.8769e+01
2025-03-13 03:27:44,079 INFO: [KUnet..][epoch:492, iter:  51,000, lr:(1.696e-04,1.697e-05,)] [eta: 3 days, 7:37:51, time (data): 0.295 (0.006)] l_pix: -1.7053e+01
